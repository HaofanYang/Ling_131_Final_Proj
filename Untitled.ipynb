{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation ##\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Train Classifiers ###\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1) Import ####\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from time import time\n",
    "from pprint import pprint\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "import mpl_toolkits.axisartist as AA\n",
    "from sklearn.externals import joblib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2) Get Dataset ####\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use a built in method in **sklearn.dataset** to downloads data from 20newsgroups api with some chosen categories (computer science, science, electronics, sports), seperates training set and testing set, finally returns them.\n",
    "\n",
    "If these files already exisits locally, it will just load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "\n",
    "    remove = ()\n",
    "    categories = 'alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space'\n",
    "\n",
    "    print('start downloading...')\n",
    "    t_start = time()\n",
    "\n",
    "    data_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=0, remove=remove)\n",
    "    data_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=0, remove=remove)\n",
    "\n",
    "    t_end = time()\n",
    "    print('downloading completed，take %.3f sec' % (t_end - t_start))\n",
    "\n",
    "    return data_train, data_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method prints type, size, and categories of training set and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start downloading...\n",
      "downloading completed，take 0.517 sec\n",
      "data type： <class 'sklearn.utils.Bunch'>\n",
      "# of texts in train set ： 2034\n",
      "# of texts in test set： 1353\n",
      "name of4 categories：\n",
      "['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "def print_data_info(data_train, data_test):\n",
    "\n",
    "    print('data type：', type(data_train))\n",
    "    print('# of texts in train set ：', len(data_train.data))\n",
    "    print('# of texts in test set：', len(data_test.data))\n",
    "    print('name of%d categories：' % len(data_train.target_names))\n",
    "\n",
    "    pprint(data_train.target_names)\n",
    "\n",
    "data_train, data_test = get_data()\n",
    "print_data_info(data_train, data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get_y_data** method simply returns the label array of training set and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_data(data_train, data_test):\n",
    "\n",
    "    y_train = data_train.target\n",
    "    y_test = data_test.target\n",
    "\n",
    "    return y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**print_examples** prints 2 example data in training set with their corrisponding categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Examples : the first 2 texts -- \n",
      "----------------\n",
      "category for text1 : alt.atheism\n",
      "\n",
      "From: healta@saturn.wwc.edu (Tammy R Healy)\n",
      "Subject: Re: note to Bobby M.\n",
      "Lines: 52\n",
      "Organization: Walla Walla College\n",
      "Lines: 52\n",
      "\n",
      "In article <1993Apr14.190904.21222@daffy.cs.wisc.edu> mccullou@snake2.cs.wisc.edu (Mark McCullough) writes:\n",
      ">From: mccullou@snake2.cs.wisc.edu (Mark McCullough)\n",
      ">Subject: Re: note to Bobby M.\n",
      ">Date: Wed, 14 Apr 1993 19:09:04 GMT\n",
      ">In article <1993Apr14.131548.15938@monu6.cc.monash.edu.au> darice@yoyo.cc.monash.edu.au (Fred Rice) writes:\n",
      ">>In <madhausC5CKIp.21H@netcom.com> madhaus@netcom.com (Maddi Hausmann) writes:\n",
      ">>\n",
      ">>>Mark, how much do you *REALLY* know about vegetarian diets?\n",
      ">>>The problem is not \"some\" B-vitamins, it's balancing proteins.  \n",
      ">>>There is also one vitamin that cannot be obtained from non-animal\n",
      ">>>products, and this is only of concern to VEGANS, who eat no\n",
      ">>>meat, dairy, or eggs.  I believe it is B12, and it is the only\n",
      ">>>problem.  Supplements are available for vegans; yes, the B12\n",
      ">>>does come from animal by-products.  If you are on an ovo-lacto\n",
      ">>>vegetarian diet (eat dairy and eggs) this is not an issue.\n",
      ">\n",
      ">I didn't see the original posting, but...\n",
      ">Yes, I do know about vegetarian diets, considering that several of my\n",
      ">close friends are devout vegetarians, and have to take vitamin supplements.\n",
      ">B12 was one of the ones I was thinking of, it has been a long time since\n",
      ">I read the article I once saw talking about the special dietary needs\n",
      ">of vegetarians so I didn't quote full numbers.  (Considering how nice\n",
      ">this place is. ;)\n",
      ">\n",
      ">>B12 can also come from whole-grain rice, I understand.  Some brands here\n",
      ">>in Australia (and other places too, I'm sure) get the B12 in the B12\n",
      ">>tablets from whole-grain rice.\n",
      ">\n",
      ">Are you sure those aren't an enriched type?  I know it is basically\n",
      ">rice and soybeans to get almost everything you need, but I hadn't heard\n",
      ">of any rice having B12.  \n",
      ">\n",
      ">>Just thought I'd contribute on a different issue from the norm :)\n",
      ">\n",
      ">You should have contributed to the programming thread earlier. :)\n",
      ">\n",
      ">> Fred Rice\n",
      ">> darice@yoyo.cc.monash.edu.au   \n",
      ">\n",
      ">M^2\n",
      ">\n",
      "If one is a vegan (a vegetarian taht eats no animal products at at i.e eggs, \n",
      "milk, cheese, etc., after about 3 years of a vegan diet, you need to start \n",
      "taking B12 supplements because b12 is found only in animals.) Acutally our \n",
      "bodies make B12, I think, but our bodies use up our own B12 after 2 or 3 \n",
      "years.  \n",
      "Lacto-oveo vegetarians, like myself, still get B12 through milk products \n",
      "and eggs, so we don't need supplements.\n",
      "And If anyone knows more, PLEASE post it.  I'm nearly contridicting myself \n",
      "with the mish-mash of knowledge I've gleaned.\n",
      "\n",
      "Tammy\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------\n",
      "category for text2 : comp.graphics\n",
      "\n",
      "From: ch381@cleveland.Freenet.Edu (James K. Black)\n",
      "Subject: NEEDED: algorithms for 2-d & 3-d object recognition\n",
      "Organization: Case Western Reserve University, Cleveland, OH (USA)\n",
      "Lines: 23\n",
      "Reply-To: ch381@cleveland.Freenet.Edu (James K. Black)\n",
      "NNTP-Posting-Host: hela.ins.cwru.edu\n",
      "\n",
      "\n",
      "Hi,\n",
      "         I have a friend who is working on 2-d and 3-d object recognition. He is looking\n",
      "for references describing algorithms on the following subject areas:\n",
      "\n",
      "Thresholding\n",
      "Edge Segmentation\n",
      "Marr-Hildreth\n",
      "Sobel Operator\n",
      "Chain Codes\n",
      "Thinning - Skeletonising\n",
      "\n",
      "If anybody is willing to post an algorithm that they have implemented which demonstrates\n",
      "any of the above topics, it would be much appreciated.\n",
      "\n",
      "Please post all replies to my e-mail address. If requested I will post a summary to the\n",
      "newsgroup in a couple of weeks.\n",
      "\n",
      "\n",
      "Thanks in advance for all replies\n",
      "\n",
      "James\n",
      "eb192@city.ac.uk\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_examples(y_train, data_train):\n",
    "\n",
    "    print(' -- Examples : the first 2 texts -- ')\n",
    "\n",
    "    categories = data_train.target_names\n",
    "\n",
    "    for i in np.arange(2):\n",
    "        print('----------------')\n",
    "        print('category for text%d : %s\\n' % (i + 1, categories[y_train[i]]))\n",
    "        print(data_train.data[i])\n",
    "        print('\\n\\n')\n",
    "\n",
    "y_train, y_test = get_y_data(data_train, data_test)\n",
    "print_examples(y_train, data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3) Fit Data using TF-IDF Model ####\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we call method **tfidf_data** to fit training set and testing set using **TF-IDF**, meanwhile save the trained data to **vec.pickle**, avoiding training classifiers every time we run the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_data(data_train, data_test):\n",
    "\n",
    "    vectorizer = TfidfVectorizer(input='content', stop_words='english', max_df=0.5, sublinear_tf=True)\n",
    "\n",
    "    vec = vectorizer.fit(data_train.data)\n",
    "    pickle.dump(vec, open(\"vec.pickle\", \"wb\"))\n",
    "    x_train = vectorizer.transform(data_train.data)  # x_train is sparse，scipy.sparse.csr.csr_matrix\n",
    "    x_test = vectorizer.transform(data_test.data)\n",
    "\n",
    "    return x_train, x_test, vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It prints size and number of features of training set after **TF-IDF** fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of train set：2034，# of features：33809\n"
     ]
    }
   ],
   "source": [
    "def print_x_data(x_train, vectorizer):\n",
    "\n",
    "    print('# of train set：%d，# of features：%d' % x_train.shape)\n",
    "    \n",
    "x_train, x_test, vectorizer = tfidf_data(data_train, data_test)\n",
    "print_x_data(x_train, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4) Train Classifier ####\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method **classifier** uses Multinomial Naive Bayes classifier, Bernoulli Naive Bayes classifier, K Neighbors classifier, Ridge Regression classifier, Random Forest classifier, Support Vector Machine classifier to classify training data. \n",
    "\n",
    "It then returns array of results of each classifier including its error rate, training time and testing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(x, y):\n",
    "    print('\\n\\n===================\\n evaluation of classifiers：\\n')\n",
    "    clfs = {\"MultinomialNB\": MultinomialNB(), \n",
    "            \"BernoulliNB\": BernoulliNB(),  \n",
    "            \"K_Neighbors\": KNeighborsClassifier(),  \n",
    "            \"Ridge_Regression\": RidgeClassifier(),  \n",
    "            \"RandomForest\": RandomForestClassifier(n_estimators=200),  \n",
    "            \"SVC\": SVC()  \n",
    "            }\n",
    "    result = []\n",
    "    for name,clf in clfs.items():\n",
    "        a = test_clf(name, clf, x, y)\n",
    "        result.append(a)\n",
    "        print('\\n')\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**test_clf**'s input is one of the classifiers. GridSearchCV object's job is to set parameters to the classifier according to type of the classifier (e.g. set **neighbors_can** when the classifier is **K Neighbors classifier**). \n",
    "\n",
    "Then it trains each classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_clf(name, clf, x_train, y_train):\n",
    "    print ('Classifier：', clf)\n",
    "    alpha_can = np.logspace(-3, 2, 10)\n",
    "    model = GridSearchCV(clf, param_grid={'alpha': alpha_can}, cv=5)\n",
    "    m = alpha_can.size\n",
    "    if hasattr(clf, 'alpha'):\n",
    "        model.set_params(param_grid={'alpha': alpha_can})\n",
    "        m = alpha_can.size\n",
    "    if hasattr(clf, 'n_neighbors'):\n",
    "        neighbors_can = np.arange(1, 15)\n",
    "        model.set_params(param_grid={'n_neighbors': neighbors_can})\n",
    "        m = neighbors_can.size\n",
    "    if hasattr(clf, 'C'):\n",
    "        C_can = np.logspace(1, 3, 3)\n",
    "        gamma_can = np.logspace(-3, 0, 3)\n",
    "        model.set_params(param_grid={'C':C_can, 'gamma':gamma_can})\n",
    "        m = C_can.size * gamma_can.size\n",
    "    if hasattr(clf, 'max_depth'):\n",
    "        max_depth_can = np.arange(4, 10)\n",
    "        model.set_params(param_grid={'max_depth': max_depth_can})\n",
    "        m = max_depth_can.size\n",
    "    t_start = time()\n",
    "    model.fit(x_train, y_train)\n",
    "    t_end = time()\n",
    "    t_train = (t_end - t_start) / (5*m)\n",
    "    print ('Training time for 5 -fold cross validation：%.3f/(5*%d) = %.3fsec' % ((t_end - t_start), m, t_train))\n",
    "    print( 'Optimal hyperparameter：', model.best_params_)\n",
    "    joblib.dump(model, \"%s.joblib\"%name)\n",
    "    t_start = time()\n",
    "    y_hat = model.predict(x_test)\n",
    "    t_end = time()\n",
    "    t_test = t_end - t_start\n",
    "    print ('Testing Time：%.3f sec' % t_test)\n",
    "    acc = metrics.accuracy_score(y_test, y_hat)\n",
    "    print ('Accuracy ：%.2f%%' % (100 * acc))\n",
    "    name = str(clf).split('(')[0]\n",
    "    index = name.find('Classifier')\n",
    "    if index != -1:\n",
    "        name = name[:index]\n",
    "    if name == 'SVC':\n",
    "        name = 'SVM'\n",
    "    return t_train, t_test, 1-acc, name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5) Render Results ####\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**draw** renders a diagram using results from previous method to evaluate results of different classifiers by listing the **error rate, training time and testing time** of each classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(result):\n",
    "    time_train1, time_test1, err1, names = result.T\n",
    "    time_test = time_test1.astype(np.float)\n",
    "    time_train = time_train1.astype(np.float)\n",
    "    err = err1.astype(np.float)\n",
    "    x= np.arange(len(time_train))\n",
    "    bar_width = 0.25\n",
    "    ax1 = host_subplot(111, axes_class=AA.Axes)\n",
    "    plt.subplots_adjust(right = 0.75)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax3 = ax1.twinx()\n",
    "    offset3 = 60\n",
    "    offset2 = 0\n",
    "\n",
    "    new_fixed_axis = ax3.get_grid_helper().new_fixed_axis\n",
    "    ax3.axis[\"right\"] = new_fixed_axis(loc=\"right\", axes=ax3, offset=(offset3, 0))\n",
    "    ax3.axis[\"right\"].toggle(all=True)\n",
    "\n",
    "    new_fixed_axis2 = ax2.get_grid_helper().new_fixed_axis\n",
    "    ax2.axis[\"right\"] = new_fixed_axis2(loc=\"right\", axes=ax2, offset=(offset2, 0))\n",
    "    ax2.axis[\"right\"].toggle(all=True)\n",
    "\n",
    "    ax1.set_ylabel(\"Error percentage\")\n",
    "    ax2.set_ylabel(\"Training time\")\n",
    "    ax3.set_ylabel(\"Testing time\")\n",
    "\n",
    "    b1 = ax1.bar(x, err, bar_width, alpha=0.2, color='r')\n",
    "    b2 = ax2.bar(x + bar_width, time_train, bar_width, alpha=0.2, color='g')\n",
    "    b3 = ax3.bar(x + bar_width * 2, time_test, bar_width, alpha=0.2, color='b')\n",
    "    plt.xticks(x + bar_width * 2, names)\n",
    "    plt.legend([b1[0], b2[0], b3[0]], ('Error Percentage', 'Training Time', 'Testing Time'), loc='upper left')\n",
    "    plt.xlabel('Different Types Of Classifiers')\n",
    "    plt.title('Evaluation Of Different Classifiers')\n",
    "    plt.savefig(\"Performance_his.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application\n",
    "\n",
    "\n",
    "get_data:\n",
    "    This method downloads data from 20newsgroups api with some chosen categories (computer science, science, electronics, sports). It seperates training set and testing set, returns them afterwards.\n",
    "    \n",
    "    \n",
    "print_data_info:\n",
    "    This method prints type, size, and categories of training set and testing set.\n",
    "    \n",
    "    \n",
    "get_y_data:\n",
    "    This method simply returns the label array of training set and testing set.\n",
    "    \n",
    "    \n",
    "tfidf_data:\n",
    "    It uses TF-IDF to fit training set and testing set, meanwhile saves the trained data to vec.pickle, avoiding training classifiers every time we run the file.\n",
    "    \n",
    "    \n",
    "print_example:\n",
    "    It prints 10 example data in training set with their corrisponding categories.\n",
    "    \n",
    "    \n",
    "print_x_data:\n",
    "    This method prints size and number of features of training set after TF-IDF fit.\n",
    "    \n",
    "    \n",
    "classifier:\n",
    "    This method uses Multinomial Naive Bayes classifier, Bernoulli Naive Bayes classifier, K Neighbors classifier, Ridge Regression classifier, Random Forest classifier, Support Vector Machine classifier to classify training data. It then returns array of results of each classifier including its error rate, training time and testing time.\n",
    "    \n",
    "    \n",
    "test_clf:\n",
    "    This method's input is one of the classifiers. GridSearchCV object's job is to set parameters to the classifier according to type of the classifier (e.g. set neighbors_can when the classifier is K Neighbors classifier). Then it trains the classifier\n",
    "\n",
    "\n",
    "\n",
    "draw:\n",
    "    It uses results from method test_clf to render a diagram to evaluate results of different classifiers by listing the error rate, training time and testing time of each classifier.\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
